{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow with Estimators\n",
    "\n",
    "**dataset: iris dataset (iris.csv)**\n",
    "\n",
    "The previous Notebook shows how to build a full Multi-Layer Perceptron model with full Sessions in Tensorflow. Unfortunately, this is an extremely involved process. There has someone to manually define an entire graph with a Tensorflow session and there are so many moving pieces there that it can be really hard to wrap her mind around that. However, developers have created Estimators that have an easier to use flow! It is much easier to use, but there is a sacrifice of some level of customization of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, Tensorflow has an estimator object which can used to quickly create models without needing to make the graph.\n",
    "\n",
    "Below are the Estimator steps that look like the sckit-learn's workflow:\n",
    "* Read in Data (normalize if necessary)\n",
    "* Train/test split the data\n",
    "* Create Estimator Feature Columns (list of specialized feature columns)\n",
    "* Create Input Estimator Function (way of organizing the training data)\n",
    "* Train Estimator Model\n",
    "* Predict with new Test Input Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the Tensorflow Estimator object, there are some things to be changed:\n",
    "* the column names must not have spaces or special characters --> Renaming the columns\n",
    "* the \"target\" column values for classification must be an integer (now they are floats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### renaming the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2     0.0\n",
       "1           4.9          3.0           1.4          0.2     0.0\n",
       "2           4.7          3.2           1.3          0.2     0.0\n",
       "3           4.6          3.1           1.5          0.2     0.0\n",
       "4           5.0          3.6           1.4          0.2     0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "target          150 non-null float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 5.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the 'target' column must be transformed to an integer which is the target/label of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['target'] = df['target'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  target\n",
       "0           5.1          3.5           1.4          0.2       0\n",
       "1           4.9          3.0           1.4          0.2       0\n",
       "2           4.7          3.2           1.3          0.2       0\n",
       "3           4.6          3.1           1.5          0.2       0\n",
       "4           5.0          3.6           1.4          0.2       0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'target'column is actually a binary class that has to be an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "120    2\n",
       "121    2\n",
       "122    2\n",
       "123    2\n",
       "124    2\n",
       "125    2\n",
       "126    2\n",
       "127    2\n",
       "128    2\n",
       "129    2\n",
       "130    2\n",
       "131    2\n",
       "132    2\n",
       "133    2\n",
       "134    2\n",
       "135    2\n",
       "136    2\n",
       "137    2\n",
       "138    2\n",
       "139    2\n",
       "140    2\n",
       "141    2\n",
       "142    2\n",
       "143    2\n",
       "144    2\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: target, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The class values are sorted and organized in order. A shuffle must take place later on otherwise all the zeros, all the ones, and all the twos, will feed the model at once, which is not right.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing the train_test_split from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_test_split is shuffling the data by default\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all the columns\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing in every column in a list of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "\n",
    "for col in X.columns:\n",
    "    feat_cols.append(tf.feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choosing 'numeric_column' because everything I'm dealing with is numeric. The 'col' is actually the header of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='sepal_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='sepal_width', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='petal_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='petal_width', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: NumericColumn objects with keys that corresponds to a column of the Pandas dataframe. They are also in the same order as in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I have a Pandas dataframe, the input function creation is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=30, num_epochs=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args:\n",
    "- x: pandas DataFrame object --> the *X* training data\n",
    "- y: pandas Series object or DataFrame. None if absent --> the *y* test data\n",
    "- batch_size: int, size of batches to return.\n",
    "- num_epochs: int, number of epochs to iterate over data. If not None, read attempts that would exceed this value will raise OutOfRangeError. (Here, epochs are equal to 5, that means if I've already gone through every single training point, and I've done that at least five times (basically gone through all the training data at least a total of five times), then I'm going to be done training that TF estimator even if I've hit the number of steps I previously indicated in the estimator)\n",
    "- shuffle: bool, whether to read the records in random order. (i.e. shuffling the data if it is sorted. In my case, the data was shuffled before already by the *train_test_split* function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the estimator which is actually the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/xt/qt7qwvmn7g72_vlkm345vl3w0000gn/T/tmpr3t7e4k6\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/xt/qt7qwvmn7g72_vlkm345vl3w0000gn/T/tmpr3t7e4k6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2f2604a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# DNNClassifier = Deep Neural Network Classifier\n",
    "classifier = tf.estimator.DNNClassifier(hidden_units=[10, 20, 10, 10], n_classes=3, feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args:\n",
    "- hidden_units: a list with number of neurons at each hidden layer\n",
    "- n_classes: the number of classes that are at the target column (e.g. the Iris dataset has 3 classes of flowers)\n",
    "- feature_columns: the list of numeric columns that was created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training the Classifier/Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/xt/qt7qwvmn7g72_vlkm345vl3w0000gn/T/tmpr3t7e4k6/model.ckpt.\n",
      "INFO:tensorflow:loss = 33.381947, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 18 into /var/folders/xt/qt7qwvmn7g72_vlkm345vl3w0000gn/T/tmpr3t7e4k6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13.031017.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1a2f260d68>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=input_func, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args:\n",
    "- input_fn: the Input Function\n",
    "- steps: the number of steps to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All these done here are the relevant Session and Graph creation that was shown in the previous Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the Input Function for the test data now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=len(X_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Args:\n",
    "- x: X_test --> the test data\n",
    "- y: There is no *y* because these will be the prediction values\n",
    "- batch_size: the length of the X_test, i.e. every value will be parsed only once, for each point, because there is no training process executed here. Every will be done in one large batch\n",
    "- shuffle: False --> there is no need to shuffling anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using the predict method from the classifier model to creating predictions from X_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/xt/qt7qwvmn7g72_vlkm345vl3w0000gn/T/tmpr3t7e4k6/model.ckpt-18\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# the class predict is a generator, so I cast this to a list\n",
    "predictions = list(classifier.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the predictions list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-0.7010647 , -0.26639065, -0.43647546], dtype=float32),\n",
       "  'probabilities': array([0.25991884, 0.40143412, 0.33864713], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.9856693 , -0.24002543,  0.21923605], dtype=float32),\n",
       "  'probabilities': array([0.06329522, 0.36265558, 0.5740492 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.2662017 , -0.25905615,  0.26402295], dtype=float32),\n",
       "  'probabilities': array([0.04762273, 0.35441053, 0.5979667 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.5606167 , -0.30481198,  0.33148357], dtype=float32),\n",
       "  'probabilities': array([0.03499672, 0.33397263, 0.63103074], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.84717  , -0.3347275,  0.3808703], dtype=float32),\n",
       "  'probabilities': array([0.02593012, 0.3198486 , 0.65422124], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.124029  , -0.37338915,  0.43867704], dtype=float32),\n",
       "  'probabilities': array([0.0192637 , 0.30152777, 0.6792086 ], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.924984 , -0.6834919, -0.9406613], dtype=float32),\n",
       "  'probabilities': array([0.73801357, 0.14774477, 0.11424176], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.463909  , -0.3114945 ,  0.31798187], dtype=float32),\n",
       "  'probabilities': array([0.0388272, 0.3341318, 0.627041 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.356548  , -0.28599396,  0.28948507], dtype=float32),\n",
       "  'probabilities': array([0.04342688, 0.34434104, 0.61223215], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.4568993 , -0.18409023, -0.11541152], dtype=float32),\n",
       "  'probabilities': array([0.11911002, 0.4253263 , 0.4555636 ], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-1.0056347 , -0.22039157, -0.28326362], dtype=float32),\n",
       "  'probabilities': array([0.1903946, 0.4175239, 0.3920815], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-0.9583896, -0.2177451, -0.2690341], dtype=float32),\n",
       "  'probabilities': array([0.19647454, 0.41206345, 0.39146197], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.3274014 , -0.25673524,  0.27275768], dtype=float32),\n",
       "  'probabilities': array([0.04465085, 0.35408598, 0.6012631 ], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.90998966, -0.67471063, -0.91998017], dtype=float32),\n",
       "  'probabilities': array([0.73237133, 0.15014288, 0.11748583], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.5767543 , -0.28087118,  0.31348157], dtype=float32),\n",
       "  'probabilities': array([0.03456528, 0.34334406, 0.62209064], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.81979185, -0.5863385 , -0.86089015], dtype=float32),\n",
       "  'probabilities': array([0.69864756, 0.17123145, 0.13012096], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.13321   , -0.23613164,  0.22370425], dtype=float32),\n",
       "  'probabilities': array([0.05487055, 0.36578846, 0.57934093], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.822124 , -0.5959595, -0.8520864], dtype=float32),\n",
       "  'probabilities': array([0.6994798 , 0.16939843, 0.13112178], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.5469538 , -0.18920651, -0.0431117 ], dtype=float32),\n",
       "  'probabilities': array([0.10653748, 0.4141566 , 0.47930586], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.998801  , -0.33331266,  0.40853295], dtype=float32),\n",
       "  'probabilities': array([0.02194926, 0.3155198 , 0.66253084], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.2156315, -0.2599838,  0.2574636], dtype=float32),\n",
       "  'probabilities': array([0.05018168, 0.35470903, 0.59510934], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.785013  , -0.31188306,  0.36586308], dtype=float32),\n",
       "  'probabilities': array([0.02761209, 0.32746574, 0.64492214], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.9493745 , -0.7452175 , -0.95563984], dtype=float32),\n",
       "  'probabilities': array([0.75047207, 0.13784233, 0.11168564], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.0514014 , -0.23671451,  0.21351802], dtype=float32),\n",
       "  'probabilities': array([0.05963207, 0.3660904 , 0.5742775 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.4776196 , -0.28505555,  0.3087879 ], dtype=float32),\n",
       "  'probabilities': array([0.03819595, 0.3421651 , 0.61963886], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.8630689 , -0.22725466,  0.17653969], dtype=float32),\n",
       "  'probabilities': array([0.07235242, 0.37143105, 0.5562165 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.7217972 , -0.3051739 ,  0.35749415], dtype=float32),\n",
       "  'probabilities': array([0.02945427, 0.33012196, 0.64042383], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.4580845 , -0.16808033, -0.0873878 ], dtype=float32),\n",
       "  'probabilities': array([0.11667393, 0.42385325, 0.4594728 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.7995074 , -0.3403103 ,  0.37920567], dtype=float32),\n",
       "  'probabilities': array([0.02723961, 0.31857863, 0.6541818 ], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.9208477 , -0.67104965, -0.94877434], dtype=float32),\n",
       "  'probabilities': array([0.73652834, 0.14991228, 0.11355936], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.7416102 , -0.18226835, -0.04379612], dtype=float32),\n",
       "  'probabilities': array([0.08914495, 0.42394575, 0.48690924], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.8747702 , -0.36979362,  0.416936  ], dtype=float32),\n",
       "  'probabilities': array([0.02491779, 0.30507526, 0.670007  ], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.8255741 , -0.60190135, -0.84919643], dtype=float32),\n",
       "  'probabilities': array([0.7006408 , 0.16809343, 0.13126586], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.7244188 , -0.18539199, -0.06886625], dtype=float32),\n",
       "  'probabilities': array([0.0917766 , 0.42768377, 0.48053968], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-0.76935136, -0.25612122, -0.3751073 ], dtype=float32),\n",
       "  'probabilities': array([0.24073522, 0.40219128, 0.35707355], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.94099087, -0.67750096, -0.97874355], dtype=float32),\n",
       "  'probabilities': array([0.74358106, 0.14737582, 0.10904311], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.8712298 , -0.22230446,  0.1603958 ], dtype=float32),\n",
       "  'probabilities': array([0.07231776, 0.3761527 , 0.5515295 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.5154433 , -0.26489404,  0.3110564 ], dtype=float32),\n",
       "  'probabilities': array([0.03652408, 0.3467212 , 0.6167547 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-1.2591199 , -0.19440642, -0.17669691], dtype=float32),\n",
       "  'probabilities': array([0.1459464 , 0.4232457 , 0.43080795], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.1029096 , -0.21829844,  0.11960895], dtype=float32),\n",
       "  'probabilities': array([0.05947304, 0.3915582 , 0.54896873], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.4426944 , -0.30646083,  0.31115314], dtype=float32),\n",
       "  'probabilities': array([0.03972917, 0.3364062 , 0.6238646 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-2.882048  , -0.29657558,  0.37153482], dtype=float32),\n",
       "  'probabilities': array([0.02490507, 0.33047923, 0.64461565], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.7876294 , -0.55885583, -0.83260345], dtype=float32),\n",
       "  'probabilities': array([0.6858684 , 0.17843074, 0.13570087], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.86950684, -0.64127684, -0.8831432 ], dtype=float32),\n",
       "  'probabilities': array([0.71733385, 0.15834206, 0.12432404], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 0.9187276, -0.6882384, -0.9191108], dtype=float32),\n",
       "  'probabilities': array([0.73548007, 0.14746007, 0.11705981], dtype=float32)}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([1]),\n",
       " 'classes': array([b'1'], dtype=object),\n",
       " 'logits': array([-0.7010647 , -0.26639065, -0.43647546], dtype=float32),\n",
       " 'probabilities': array([0.25991884, 0.40143412, 0.33864713], dtype=float32)}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creating a more structured list of predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "\n",
    "for prediction in predictions:\n",
    "    final_predictions.append(prediction['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a Classification Report and a Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[11  0  0]\n",
      " [ 0  4 12]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test,final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      0.25      0.40        16\n",
      "          2       0.60      1.00      0.75        18\n",
      "\n",
      "avg / total       0.84      0.73      0.69        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report:')\n",
    "print(classification_report(y_test,final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with the Input Function's *batch_size* argument of the training data and the *hidden_units* (i.e. the hidden layers) argument of the Classifier, there can be yielded better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
