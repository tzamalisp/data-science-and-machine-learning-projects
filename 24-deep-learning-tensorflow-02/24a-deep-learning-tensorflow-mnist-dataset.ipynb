{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Multi-Layer Perceptron\n",
    "\n",
    "#### built-in dataset: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_dataput_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/mnist-data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking the type of mnist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " it is a Tensoflow object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grabbing the images (all the arrays):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55000 images and each image is an array of 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grabbing an image (an array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02352941, 0.76470596,\n",
       "       0.9960785 , 1.        , 0.93725497, 0.1137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02352941, 0.6392157 , 0.9960785 , 0.9960785 , 0.6862745 ,\n",
       "       0.21568629, 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.47450984, 0.9960785 ,\n",
       "       0.9960785 , 0.5803922 , 0.03137255, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.54901963, 0.9294118 ,\n",
       "       0.43921572, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16862746, 0.9607844 , 0.9960785 , 0.9490197 , 0.01568628,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.20784315, 0.92549026, 0.9960785 , 0.43921572, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6431373 , 0.9960785 ,\n",
       "       0.9803922 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.97647065, 0.1254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.83921576, 0.9960785 , 0.69803923, 0.        ,\n",
       "       0.        , 0.01176471, 0.03529412, 0.03529412, 0.03529412,\n",
       "       0.17254902, 0.909804  , 0.9960785 , 0.64705884, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.83921576,\n",
       "       0.9960785 , 0.7254902 , 0.        , 0.21176472, 0.7294118 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9058824 , 0.16862746, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.37647063, 0.9960785 , 0.9803922 ,\n",
       "       0.74509805, 0.98823535, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.50980395, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.49411768, 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7803922 , 0.46274513, 0.5686275 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.30588236, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.10980393, 0.47058827,\n",
       "       0.47058827, 0.47058827, 0.1254902 , 0.01176471, 0.        ,\n",
       "       0.47450984, 0.9960785 , 0.9960785 , 0.76470596, 0.01568628,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.43137258, 0.9960785 ,\n",
       "       0.9960785 , 0.33333334, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.41960788, 0.9960785 , 0.98823535, 0.19215688,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.8235295 ,\n",
       "       0.9960785 , 0.7176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05882353, 0.87843144, 0.9960785 , 0.2784314 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.27058825,\n",
       "       0.9960785 , 0.97647065, 0.20784315, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8470589 , 0.9960785 , 0.92549026,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8745099 , 0.9960785 , 0.74509805, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.8745099 , 0.9960785 ,\n",
       "       0.73333335, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.8745099 , 0.9960785 , 0.97647065, 0.49411768,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.44705886,\n",
       "       0.9333334 , 0.9960785 , 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a vector!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the image and visualize the data how it looks like a reshaping of that array must take place, i.e. reshaping to 28x28, because: 28 * 28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.76470596, 0.9960785 , 1.        , 0.93725497,\n",
       "        0.1137255 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.02352941,\n",
       "        0.6392157 , 0.9960785 , 0.9960785 , 0.6862745 , 0.21568629,\n",
       "        0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.47450984,\n",
       "        0.9960785 , 0.9960785 , 0.5803922 , 0.03137255, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "        0.9294118 , 0.43921572, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.16862746, 0.9607844 ,\n",
       "        0.9960785 , 0.9490197 , 0.01568628, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20784315, 0.92549026,\n",
       "        0.9960785 , 0.43921572, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6431373 , 0.9960785 ,\n",
       "        0.9803922 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "        0.97647065, 0.1254902 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.83921576, 0.9960785 ,\n",
       "        0.69803923, 0.        , 0.        , 0.01176471, 0.03529412,\n",
       "        0.03529412, 0.03529412, 0.17254902, 0.909804  , 0.9960785 ,\n",
       "        0.64705884, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.83921576, 0.9960785 ,\n",
       "        0.7254902 , 0.        , 0.21176472, 0.7294118 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9058824 ,\n",
       "        0.16862746, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37647063, 0.9960785 ,\n",
       "        0.9803922 , 0.74509805, 0.98823535, 0.9960785 , 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.50980395,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.49411768, 0.9960785 ,\n",
       "        0.9960785 , 0.9960785 , 0.9960785 , 0.7803922 , 0.46274513,\n",
       "        0.5686275 , 0.9960785 , 0.9960785 , 0.9960785 , 0.30588236,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10980393, 0.47058827,\n",
       "        0.47058827, 0.47058827, 0.1254902 , 0.01176471, 0.        ,\n",
       "        0.47450984, 0.9960785 , 0.9960785 , 0.76470596, 0.01568628,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43137258, 0.9960785 , 0.9960785 , 0.33333334, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.41960788, 0.9960785 , 0.98823535, 0.19215688, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.8235295 , 0.9960785 , 0.7176471 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05882353,\n",
       "        0.87843144, 0.9960785 , 0.2784314 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.27058825,\n",
       "        0.9960785 , 0.97647065, 0.20784315, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8470589 ,\n",
       "        0.9960785 , 0.92549026, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.9960785 , 0.74509805, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.9960785 , 0.73333335, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.8745099 ,\n",
       "        0.9960785 , 0.97647065, 0.49411768, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.44705886,\n",
       "        0.9333334 , 0.9960785 , 0.48627454, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are from 0 to 1, which represents the darkeness of the pixels in that array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image = mnist.train.images[2].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c35495668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wu8bdOD0FPzFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c352fdfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c3553a588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADXFJREFUeJzt3X+IXfWZx/HPJz+KkDTEkNFEE51u\nEVkRmixDWHFdXEqiXQtJwZpGKRFLE6FqC/nDMKjRPxbjatNVXCrpOjRCaxtITAJKtyILWliCo0i1\nTbvROLZpYjIxhVqDliTP/jEnZRrnnju599x77uR5vyDce89zfjwe5zPn3vnee7+OCAHIZ1rdDQCo\nB+EHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5DUjG4ebP78+dHf39/NQwKpjIyM6NixY57Mum2F\n3/aNkh6XNF3Sf0XE5rL1+/v7NTw83M4hAZQYGBiY9LotP+23PV3Sf0r6kqSrJK2xfVWr+wPQXe28\n5l8m6e2IOBARf5H0E0krq2kLQKe1E/5LJf1+3OODxbK/YXud7WHbw6Ojo20cDkCV2gn/RH9U+NTn\ngyNia0QMRMRAX19fG4cDUKV2wn9Q0uJxjxdJOtReOwC6pZ3wvyrpCtufs/0ZSV+TtKeatgB0WstD\nfRFx0vZdkv5bY0N9QxHxq8o6A9BRbY3zR8QLkl6oqBcAXcTbe4GkCD+QFOEHkiL8QFKEH0iK8ANJ\nEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivAD\nSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iqrVl6bY9I+lDSKUknI2KgiqYAdF5b4S/8S0Qcq2A/\nALqIp/1AUu2GPyT93PZrttdV0RCA7mj3af+1EXHI9kWSXrT9m4h4efwKxS+FdZJ02WWXtXk4AFVp\n68ofEYeK26OSnpO0bIJ1tkbEQEQM9PX1tXM4ABVqOfy2Z9n+7Jn7klZIequqxgB0VjtP+y+W9Jzt\nM/v5cUT8rJKuAHRcy+GPiAOSvlBhL2jg1KlTpfVVq1Y1rD3//POl20ZEaX3evHml9Xfffbe0PmfO\nnNI66sNQH5AU4QeSIvxAUoQfSIrwA0kRfiCpKj7VhzY1G8rbsGFDab3ZcF6ZO+64o7R+//33l9Zn\nz57d8rE77aOPPmpYmzVrVhc76U1c+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcb5e8C2bdtK6088\n8UTL+37ggQdK6/fdd19pfcaM3v0ReeSRR0rrjz32WMPak08+Wbrt6tWrW+ppKuHKDyRF+IGkCD+Q\nFOEHkiL8QFKEH0iK8ANJ9e4g7nnk/fffL63fc889be2/7Ouxm43zT5vWu7//33vvvdL6li1bSusf\nfPBBle2cd3r3/zyAjiL8QFKEH0iK8ANJEX4gKcIPJEX4gaSajvPbHpL0ZUlHI+LqYtk8ST+V1C9p\nRNItEfHHzrU5tT388MOl9RMnTpTWm32mfu/evQ1rvTyO30yzz+uPjo6W1mfOnNmwdsMNN7TU0/lk\nMj8ZP5R041nLNkp6KSKukPRS8RjAFNI0/BHxsqTjZy1eKenM189sk7Sq4r4AdFirzwkvjojDklTc\nXlRdSwC6oeMvCG2vsz1se7jZazQA3dNq+I/YXihJxe3RRitGxNaIGIiIgb6+vhYPB6BqrYZ/j6S1\nxf21knZX0w6AbmkaftvPSvpfSVfaPmj7G5I2S1pue7+k5cVjAFNI03H+iFjToPTFins5b73yyitt\nbX/rrbeW1q+88sqW93369OnS+qlTp1redzPNPm+/e3d7TyjXr1/fsDZ37ty29n0+mLrvAAHQFsIP\nJEX4gaQIP5AU4QeSIvxAUnx19xTwySeftLxts6+/vvfee0vr27dvb/nYnXbJJZeU1gcHB7vUydTE\nlR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKcvwseffTR0vry5ctL6zt27Cit33zzzQ1ru3btKt22\n2Ud6e9nGjeVfGr1gwYIudTI1ceUHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY5++C/fv3t7X9yZMn\nS+s7d+5sed8rVqworTf72vBm3xewadOmc+5psq655pqO7TsDrvxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kFTTcX7bQ5K+LOloRFxdLHtQ0jcljRarDUbEC51qcqprNlZ+wQUXdOzYq1atKq3PmTOntD5t\nWvn1YWho6Jx7mqybbrqptL506dKOHTuDyVz5fyjpxgmWfy8ilhT/CD4wxTQNf0S8LOl4F3oB0EXt\nvOa/y/YvbQ/ZvrCyjgB0Ravh/76kz0taIumwpO82WtH2OtvDtodHR0cbrQagy1oKf0QciYhTEXFa\n0g8kLStZd2tEDETEQF9fX6t9AqhYS+G3vXDcw69IequadgB0y2SG+p6VdL2k+bYPStok6XrbSySF\npBFJ6zvYI4AOaBr+iFgzweKnO9DLeavZWPrtt9/enUY6oNl/WzsGBwdL683eg4BynD0gKcIPJEX4\ngaQIP5AU4QeSIvxAUnx1N9oyY0brP0LNhuoWL17c8r7RHFd+ICnCDyRF+IGkCD+QFOEHkiL8QFKE\nH0iKcX60ZfPmzS1vu3r16tL6okWLWt43muPKDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJMc6PUh9/\n/HFp/dixYy3ve+PGjS1vi/Zx5QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpJqO89teLOkZSQsknZa0\nNSIetz1P0k8l9UsakXRLRPyxc62iDu+8805p/cCBA6X1mTNnNqx1cnpvNDeZK/9JSRsi4u8l/aOk\nb9m+StJGSS9FxBWSXioeA5gimoY/Ig5HxOvF/Q8l7ZN0qaSVkrYVq22TtKpTTQKo3jm95rfdL2mp\npL2SLo6Iw9LYLwhJF1XdHIDOmXT4bc+WtEPSdyLiT+ew3Trbw7aHR0dHW+kRQAdMKvy2Z2os+D+K\niJ3F4iO2Fxb1hZKOTrRtRGyNiIGIGOjr66uiZwAVaBp+25b0tKR9EbFlXGmPpLXF/bWSdlffHoBO\nmcxHeq+V9HVJb9p+o1g2KGmzpO22vyHpd5K+2pkWUafbbrutre3nzp3bsHb55Ze3tW+0p2n4I+IX\nktyg/MVq2wHQLbzDD0iK8ANJEX4gKcIPJEX4gaQIP5AUX92NUidOnGhr++uuu66iTlA1rvxAUoQf\nSIrwA0kRfiApwg8kRfiBpAg/kBTj/Oio6dOn190CGuDKDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ\nMc6Pjtq1a1fD2lNPPVW67Z133ll1OxiHKz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNV0nN/2YknP\nSFog6bSkrRHxuO0HJX1T0mix6mBEvNCpRlGPhx56qLR+9913l9aPHz/esMZn/es1mTf5nJS0ISJe\nt/1ZSa/ZfrGofS8iHutcewA6pWn4I+KwpMPF/Q9t75N0aacbA9BZ5/Sa33a/pKWS9haL7rL9S9tD\nti9ssM0628O2h0dHRydaBUANJh1+27Ml7ZD0nYj4k6TvS/q8pCUae2bw3Ym2i4itETEQEQN9fX0V\ntAygCpMKv+2ZGgv+jyJipyRFxJGIOBURpyX9QNKyzrUJoGpNw2/bkp6WtC8itoxbvnDcal+R9Fb1\n7QHolMn8tf9aSV+X9KbtN4plg5LW2F4iKSSNSFrfkQ5RqzVr1rRVR++azF/7fyHJE5QY0wemMN7h\nByRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSMoR0b2D2aOS\n3hu3aL6kY11r4Nz0am+92pdEb62qsrfLI2JS35fX1fB/6uD2cEQM1NZAiV7trVf7kuitVXX1xtN+\nICnCDyRVd/i31nz8Mr3aW6/2JdFbq2rprdbX/ADqU/eVH0BNagm/7Rtt/9b227Y31tFDI7ZHbL9p\n+w3bwzX3MmT7qO23xi2bZ/tF2/uL2wmnSauptwdt/6E4d2/Y/teaelts+39s77P9K9vfLpbXeu5K\n+qrlvHX9ab/t6ZL+T9JySQclvSppTUT8uquNNGB7RNJARNQ+Jmz7nyX9WdIzEXF1sezfJR2PiM3F\nL84LI+LeHuntQUl/rnvm5mJCmYXjZ5aWtErS7arx3JX0dYtqOG91XPmXSXo7Ig5ExF8k/UTSyhr6\n6HkR8bKksye4XylpW3F/m8Z+eLquQW89ISIOR8Trxf0PJZ2ZWbrWc1fSVy3qCP+lkn4/7vFB9daU\n3yHp57Zfs72u7mYmcHExbfqZ6dMvqrmfszWdubmbzppZumfOXSszXletjvBPNPtPLw05XBsR/yDp\nS5K+VTy9xeRMaubmbplgZume0OqM11WrI/wHJS0e93iRpEM19DGhiDhU3B6V9Jx6b/bhI2cmSS1u\nj9bcz1/10szNE80srR44d70043Ud4X9V0hW2P2f7M5K+JmlPDX18iu1ZxR9iZHuWpBXqvdmH90ha\nW9xfK2l3jb38jV6ZubnRzNKq+dz12ozXtbzJpxjK+A9J0yUNRcS/db2JCdj+O41d7aWxSUx/XGdv\ntp+VdL3GPvV1RNImSbskbZd0maTfSfpqRHT9D28NerteY09d/zpz85nX2F3u7Z8kvSLpTUmni8WD\nGnt9Xdu5K+lrjWo4b7zDD0iKd/gBSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0jq/wE+oLZkK4hK\nXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3531b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image2 = mnist.train.images[190].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c358c1be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRF+ICjCDwRF+IGgCD8Q1P8DmswLOpm7jhAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c35760400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_image2, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining parameters for using them later on the multi-layer perceptron model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how quickly the cost function is adjusted, i.e. how quickly do you want to apply that optimization function\n",
    "learning_rate = 0.001\n",
    "\n",
    "# the training cycles\n",
    "training_epochs = 15\n",
    "\n",
    "# the size of the batches of the training data\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network parameters that define how will the neural network look like (i.e. this multi-layer perceptron)\n",
    "# the lower the rate the higher the possibility for accurate training results, but that comes at the cost \n",
    "# of having to wait as far as physical time for the results.\n",
    "\n",
    "# number of classes: here 10, because the classes are the numbers between 0 to 9\n",
    "n_classes = 10\n",
    "\n",
    "# number of samples: it is 55000 or it can defined as follows\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of neurons in the two hidden layers that will be used\n",
    "n_hidden_1 = 256  # 256, because that's the way computers store image information (8-bit color storage)\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning process\n",
    "1) receiving the input data array (of 784) and sending it to the first hidden layer of 256 neurons\n",
    "\n",
    "2) the data will begin to have a weight attached to it between the layers\n",
    "\n",
    "3) a bias is also added along with that\n",
    "\n",
    "4) then it continues to the next hidden layer until it reaches the final output layer (the more the hidden layer, the more the model will take to run, but with more hidden layers there is a possibility of being more accurate on the training data --> trade-off)\n",
    "\n",
    "5) a loss function (or cost function) is used to see how far from the original data the output (or the desired results) is --> evaluation --> that's where the reinforcement process comes in\n",
    "\n",
    "6) applying an optimization function to minimum the loss, or reducing the error (this is done by adjusting the weight values accordinly accross the entire network) --> using an Optimizer: Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a function for multi-layer perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# starting with two hidden layers using also the RELU activation function --> returns X or 0\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \"\"\"\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: Dict of bias values\n",
    "    \"\"\"\n",
    "    # 1st hidden layer with RELU Activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # x --> data input\n",
    "    # matmul() --> matrix multiplication --> h1: the first set of weights (it will be set up later on)\n",
    "    # add() --> adding a bias\n",
    "    # From theory of neural networks: X * weight + bias --> or else --> X * W + B\n",
    "    \n",
    "    # RELU(X * W + B) --> f(x) = max(0, x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # 2nd hidden layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer\n",
    "    output_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELU: https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "\n",
    "RELU: https://medium.com/tinymind/a-practical-guide-to-relu-b83ca804f1f7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially Tensorflow has what's known as a graph object that can become aware of the states of all the variables. A variable is a modifiable tensor that lives in tensorflow's graph of interacting operations. It can be used and even modified by the computation, as well as it will generally have the model parameters be variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating weights dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.random_normal: outputs random values from a normal distribution\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_14:0' shape=(784, 256) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_15:0' shape=(256, 256) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_16:0' shape=(256, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the neural network will look like the array below:\n",
    "\n",
    "[0 0 0 0 0 0 1 0 0 0]\n",
    "\n",
    " 0 - 9 (10 numbers) --> Where the index of the array has the value of 1, that means that the output is that number. The above example indicates the number 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating biases dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating placeholder for input x and output y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])  # 1st argument: data type, 2nd argument: shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### constructing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x=x, weights=weights, biases=biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining cost and optimization functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another convenient function is *next_batch*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a sample batch of 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a tuple of ten samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.next_batch(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.next_batch(10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.next_batch(10)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a banch of 10 samples of the actual training data: meaning that 784 are 28^2.\n",
    "\n",
    "the first item is a 784 long array and the second is the actual sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsample, ysample = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a ssample batch of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsample1, ysample1 = t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.12156864, 0.13333334,\n",
       "        0.454902  , 0.7490196 , 0.9960785 , 0.9921569 , 0.9921569 ,\n",
       "        0.9568628 , 0.19607845, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24313727, 0.96470594, 0.98823535, 0.98823535, 0.98823535,\n",
       "        0.9921569 , 0.98823535, 0.98823535, 0.98823535, 0.6431373 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5137255 , 0.98823535,\n",
       "        0.98823535, 0.98823535, 0.98823535, 0.9921569 , 0.98823535,\n",
       "        0.98823535, 0.98823535, 0.41960788, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.77647066, 0.98823535, 0.98823535, 0.98823535,\n",
       "        0.98823535, 0.9921569 , 0.98823535, 0.98823535, 0.9058824 ,\n",
       "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42352945,\n",
       "        0.75294125, 0.34509805, 0.34509805, 0.34509805, 0.43137258,\n",
       "        0.98823535, 0.98823535, 0.61960787, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13333334, 0.98823535, 0.98823535,\n",
       "        0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34117648, 0.98823535, 0.98823535, 0.47450984, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.63529414, 0.98823535,\n",
       "        0.98823535, 0.40000004, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.13333334, 0.9921569 , 0.98823535, 0.8705883 , 0.02745098,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43529415, 0.9921569 ,\n",
       "        0.98823535, 0.4156863 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49411768, 1.        , 0.9921569 , 0.17254902,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08235294, 0.8980393 ,\n",
       "        0.9921569 , 0.8078432 , 0.0509804 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.47450984, 0.98823535, 0.9921569 , 0.56078434,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01568628, 0.7568628 ,\n",
       "        0.98823535, 0.9803922 , 0.27450982, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.27058825, 0.98823535, 0.98823535, 0.86274517,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.9058824 ,\n",
       "        0.98823535, 0.98823535, 0.7137255 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04705883, 0.98823535, 0.98823535, 0.98823535,\n",
       "        0.227451  , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.04705883,\n",
       "        0.98823535, 0.98823535, 0.98823535, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3647059 , 0.98823535, 0.98823535,\n",
       "        0.8588236 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10196079, 0.98823535, 0.98823535, 0.37254903, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.12156864, 0.13333334, 0.454902  , 0.7490196 , 0.9960785 ,\n",
       "        0.9921569 , 0.9921569 , 0.9568628 , 0.19607845, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313727,\n",
       "        0.96470594, 0.98823535, 0.98823535, 0.98823535, 0.9921569 ,\n",
       "        0.98823535, 0.98823535, 0.98823535, 0.6431373 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5137255 ,\n",
       "        0.98823535, 0.98823535, 0.98823535, 0.98823535, 0.9921569 ,\n",
       "        0.98823535, 0.98823535, 0.98823535, 0.41960788, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.77647066,\n",
       "        0.98823535, 0.98823535, 0.98823535, 0.98823535, 0.9921569 ,\n",
       "        0.98823535, 0.98823535, 0.9058824 , 0.01568628, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42352945,\n",
       "        0.75294125, 0.34509805, 0.34509805, 0.34509805, 0.43137258,\n",
       "        0.98823535, 0.98823535, 0.61960787, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "        0.98823535, 0.98823535, 0.65882355, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34117648,\n",
       "        0.98823535, 0.98823535, 0.47450984, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.63529414,\n",
       "        0.98823535, 0.98823535, 0.40000004, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13333334, 0.9921569 ,\n",
       "        0.98823535, 0.8705883 , 0.02745098, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43529415, 0.9921569 ,\n",
       "        0.98823535, 0.4156863 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.49411768, 1.        ,\n",
       "        0.9921569 , 0.17254902, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.08235294, 0.8980393 , 0.9921569 ,\n",
       "        0.8078432 , 0.0509804 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.47450984, 0.98823535, 0.9921569 ,\n",
       "        0.56078434, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01568628, 0.7568628 , 0.98823535, 0.9803922 ,\n",
       "        0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.27058825, 0.98823535, 0.98823535, 0.86274517,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.03529412, 0.9058824 , 0.98823535, 0.98823535, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705883, 0.98823535, 0.98823535, 0.98823535, 0.227451  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705883, 0.98823535, 0.98823535, 0.98823535, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3647059 , 0.98823535, 0.98823535, 0.8588236 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10196079, 0.98823535, 0.98823535, 0.37254903, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsample1.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysample1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the ysample1 indicates the number 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c30c82940>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaIMv1SU4ZeKMvxSUYZfKur/AP6KkWCIejTeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2f17f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsample1.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is actually the number 7!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the session:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pantelistzamalis/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# old method\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new method\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Cost: 0.5510\n",
      "Epoch: 2 | Cost: 0.4681\n",
      "Epoch: 3 | Cost: 0.4416\n",
      "Epoch: 4 | Cost: 0.4460\n",
      "Epoch: 5 | Cost: 0.3724\n",
      "Epoch: 6 | Cost: 0.3205\n",
      "Epoch: 7 | Cost: 0.3383\n",
      "Epoch: 8 | Cost: 0.2875\n",
      "Epoch: 9 | Cost: 0.3002\n",
      "Epoch: 10 | Cost: 0.2442\n",
      "Epoch: 11 | Cost: 0.2464\n",
      "Epoch: 12 | Cost: 0.1970\n",
      "Epoch: 13 | Cost: 0.2645\n",
      "Epoch: 14 | Cost: 0.3125\n",
      "Epoch: 15 | Cost: 0.2064\n",
      "Model has completed 15 Epochs of training\n",
      "Time elapsed: 23.234797716140747\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # Cost (purpose is to minimize the cost)\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    # Converting the total number of batches to an integer\n",
    "    total_batch = int(n_samples/batch_size)  # 50000 samples / 100 samples for each batch size\n",
    "    \n",
    "    # now,  for every batch of data of the total batches I grab the next batch of training data and the labels\n",
    "    # using the next_batch() function\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)  # batch size = 100\n",
    "        \n",
    "        # using the feed dictionary for the optimization and cost value\n",
    "        # using _,x in a tuple, means that the first item doesn't need a value\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        # the above returns the loss (c) value\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch: {} | Cost: {:.4f}'.format(epoch+1, avg_cost))\n",
    "    \n",
    "print('Model has completed {} Epochs of training'.format(training_epochs))\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time elapsed:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Tensorflow comes with built-in function for evaluating the model, such as tf.equal(), tf.cast(), tf.reduce_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.equal() (checking how many predictions are equal to the test) --> Returns the truth value of (x == y) element-wise:\n",
    "\n",
    "argmax: https://www.tensorflow.org/api_docs/python/tf/math/argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**argmax:** Find the argmax which is equal to 1, because the output is an array of zeros and one indexed from 0 to 9 array positions ([0 0 0 0 0 1 0 0 0 0]) --> *check ysample1 variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Equal_1:0\", shape=(?,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.cast():\n",
    "To get the actual numerical value for predictions, the *tf.cast()* has to be used to cast the Tensor booleans to float point values in order to take the average of it. To take the average, a conversion of Trues to ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.reduce_mean() -->  grabbing the mean of the elements across the Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calling the MNIST test labels and images (actual values) to evaluate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing on label example\n",
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529413, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8705883 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9450981 , 0.77647066, 0.77647066, 0.77647066, 0.77647066,\n",
       "       0.77647066, 0.77647066, 0.77647066, 0.77647066, 0.6666667 ,\n",
       "       0.20392159, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705886,\n",
       "       0.28235295, 0.44705886, 0.6392157 , 0.89019614, 0.9960785 ,\n",
       "       0.882353  , 0.9960785 , 0.9960785 , 0.9960785 , 0.9803922 ,\n",
       "       0.8980393 , 0.9960785 , 0.9960785 , 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137257, 0.08235294, 0.92549026,\n",
       "       0.9960785 , 0.4156863 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.9921569 , 0.8196079 , 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.91372555,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.9960785 , 0.9333334 , 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137257, 0.97647065,\n",
       "       0.9960785 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.9960785 , 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.80392164,\n",
       "       0.9725491 , 0.227451  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411768, 0.9960785 , 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843138 ,\n",
       "       0.94117653, 0.22352943, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.86666673, 0.9960785 , 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.7960785 , 0.9960785 ,\n",
       "       0.8588236 , 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.9960785 , 0.9960785 , 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156864, 0.87843144, 0.9960785 ,\n",
       "       0.45098042, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.9960785 , 0.9960785 , 0.20392159, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2392157 , 0.9490197 , 0.9960785 ,\n",
       "       0.9960785 , 0.20392159, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.47450984, 0.9960785 , 0.9960785 , 0.8588236 , 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.47450984, 0.9960785 ,\n",
       "       0.8117648 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_accuracy = accuracy.eval({x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9569\n"
     ]
    }
   ],
   "source": [
    "print('Model Accuracy:', model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good results. However, training with more epochs (such as 10000 cycles), a better accuracy can be produced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
